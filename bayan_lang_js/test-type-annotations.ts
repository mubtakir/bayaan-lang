#!/usr/bin/env ts-node

import { Lexer } from './src/lexer/lexer';
import { Parser } from './src/parser/parser';
import { Compiler } from './src/compiler/compiler';

console.log('ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Type Annotations\n');
console.log('='.repeat(60));

// Test 1: Variable with type annotation
console.log('\n1ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ù…ØªØºÙŠØ± Ù…Ø¹ Ù†ÙˆØ¹:');
try {
  const code1 = `
Ù…ØªØºÙŠØ± Ø³: Ø±Ù‚Ù… = 5;
Ù…ØªØºÙŠØ± Ø§Ø³Ù…: Ù†Øµ = "Ø£Ø­Ù…Ø¯";
Ù…ØªØºÙŠØ± Ù†Ø´Ø·: Ù…Ù†Ø·Ù‚ÙŠ = ØµØ­ÙŠØ­;
`;
  const lexer1 = new Lexer(code1);
  const tokens1 = lexer1.tokenize();
  console.log('Tokens:', tokens1.map(t => `${t.type}:${t.value}`).join(', '));
  
  const parser1 = new Parser(tokens1);
  const ast1 = parser1.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast1, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
  console.log('Stack:', error.stack);
}

// Test 2: Function with parameter types and return type
console.log('\n2ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø§Ù„Ø© Ù…Ø¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙˆÙ†ÙˆØ¹ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:');
try {
  const code2 = `
Ø¯Ø§Ù„Ø© Ø¬Ù…Ø¹(Ø£: Ø±Ù‚Ù…ØŒ Ø¨: Ø±Ù‚Ù…): Ø±Ù‚Ù… {
  Ø§Ø±Ø¬Ø¹ Ø£ + Ø¨;
}
`;
  const lexer2 = new Lexer(code2);
  const tokens2 = lexer2.tokenize();
  console.log('Tokens:', tokens2.map(t => `${t.type}:${t.value}`).join(', '));
  const parser2 = new Parser(tokens2);
  const ast2 = parser2.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast2, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
}

// Test 3: Union types
console.log('\n3ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Union Types:');
try {
  const code3 = `
Ù…ØªØºÙŠØ± Ù‚ÙŠÙ…Ø©: Ø±Ù‚Ù… | Ù†Øµ = 5;
`;
  const lexer3 = new Lexer(code3);
  const tokens3 = lexer3.tokenize();
  const parser3 = new Parser(tokens3);
  const ast3 = parser3.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast3, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
}

// Test 4: Array types
console.log('\n4ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Array Types:');
try {
  const code4 = `
Ù…ØªØºÙŠØ± Ø£Ø±Ù‚Ø§Ù…: Ø±Ù‚Ù… = [1, 2, 3];
`;
  const lexer4 = new Lexer(code4);
  const tokens4 = lexer4.tokenize();
  const parser4 = new Parser(tokens4);
  const ast4 = parser4.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast4, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
}

// Test 5: English keywords
console.log('\n5ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:');
try {
  const code5 = `
var x: number = 5;
var name: string = "Ahmed";
var active: boolean = true;
`;
  const lexer5 = new Lexer(code5);
  const tokens5 = lexer5.tokenize();
  const parser5 = new Parser(tokens5);
  const ast5 = parser5.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast5, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
}

// Test 6: Function with English keywords
console.log('\n6ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø§Ù„Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:');
try {
  const code6 = `
function add(a: number, b: number): number {
  return a + b;
}
`;
  const lexer6 = new Lexer(code6);
  const tokens6 = lexer6.tokenize();
  const parser6 = new Parser(tokens6);
  const ast6 = parser6.parse();
  console.log('âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„');
  console.log('AST:', JSON.stringify(ast6, null, 2).substring(0, 500));
} catch (error: any) {
  console.log('âŒ ÙØ´Ù„:', error.message);
}

console.log('\n' + '='.repeat(60));
console.log('âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª!');

