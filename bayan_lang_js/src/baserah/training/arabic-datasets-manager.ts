/**
 * Ù…Ø¯ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
 * Arabic Datasets Manager for Training
 * 
 * @author Basel Yahya Abdullah
 * @description Ù†Ø¸Ø§Ù… Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©
 */

import * as fs from 'fs';
import * as path from 'path';

/**
 * Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª
 */
export interface DatasetInfo {
  name: string;
  description: string;
  source: string;
  type: 'text' | 'speech' | 'qa' | 'sentiment' | 'ner' | 'mixed';
  size: string;
  language: 'ar' | 'ar-en' | 'multi';
  license: string;
  downloadUrl?: string;
  huggingfaceId?: string;
  localPath?: string;
}

/**
 * Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
 */
export const ARABIC_DATASETS: DatasetInfo[] = [
  {
    name: 'Arabic Wikipedia',
    description: 'Ù†Ø³Ø®Ø© ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©',
    source: 'Wikipedia',
    type: 'text',
    size: '~2GB',
    language: 'ar',
    license: 'CC BY-SA 3.0',
    downloadUrl: 'https://dumps.wikimedia.org/arwiki/latest/arwiki-latest-pages-articles.xml.bz2'
  },
  {
    name: 'OSCAR Arabic',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ© Ø¶Ø®Ù…Ø© Ù…Ù† Ø§Ù„ÙˆÙŠØ¨',
    source: 'OSCAR',
    type: 'text',
    size: '~95GB',
    language: 'ar',
    license: 'CC0',
    huggingfaceId: 'oscar-corpus/OSCAR-2301'
  },
  {
    name: 'Arabic Corpus (1.5B words)',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© 1.5 Ù…Ù„ÙŠØ§Ø± ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©',
    source: 'Various',
    type: 'text',
    size: '~10GB',
    language: 'ar',
    license: 'Various'
  },
  {
    name: 'AraBERT Dataset',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ¯Ø±ÙŠØ¨ AraBERT',
    source: 'AUB MIND Lab',
    type: 'text',
    size: '~70GB',
    language: 'ar',
    license: 'MIT',
    huggingfaceId: 'aubmindlab/bert-base-arabert'
  },
  {
    name: 'CAMeLBERT Dataset',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª CAMeL Lab',
    source: 'NYU CAMeL Lab',
    type: 'text',
    size: '~167GB',
    language: 'ar',
    license: 'MIT',
    huggingfaceId: 'CAMeL-Lab/bert-base-arabic-camelbert-mix'
  },
  {
    name: 'Arabic Speech Corpus',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© ØªØ³Ø¬ÙŠÙ„Ø§Øª ØµÙˆØªÙŠØ© Ø¹Ø±Ø¨ÙŠØ©',
    source: 'Arabic Speech Corpus',
    type: 'speech',
    size: '~50 hours',
    language: 'ar',
    license: 'CC BY 4.0',
    downloadUrl: 'http://en.arabicspeechcorpus.com/arabic-speech-corpus.zip'
  },
  {
    name: 'LABR (Large Arabic Book Reviews)',
    description: 'Ù…Ø±Ø§Ø¬Ø¹Ø§Øª ÙƒØªØ¨ Ø¹Ø±Ø¨ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±',
    source: 'Mohamed Aly',
    type: 'sentiment',
    size: '~63K reviews',
    language: 'ar',
    license: 'Research',
    downloadUrl: 'https://github.com/mohamedadaly/LABR'
  },
  {
    name: 'Arabic Twitter Corpus (AJGT)',
    description: 'ØªØºØ±ÙŠØ¯Ø§Øª Ø¹Ø±Ø¨ÙŠØ©',
    source: 'Twitter',
    type: 'text',
    size: '~1M tweets',
    language: 'ar',
    license: 'Research',
    downloadUrl: 'https://github.com/komari6/Arabic-twitter-corpus-AJGT'
  },
  {
    name: 'Tashkeela Corpus',
    description: 'Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ© Ù…Ø´ÙƒÙ‘Ù„Ø©',
    source: 'Tashkeela',
    type: 'text',
    size: '~75M words',
    language: 'ar',
    license: 'GPL',
    downloadUrl: 'https://sourceforge.net/projects/tashkeela/'
  },
  {
    name: 'Arabic Question Answering',
    description: 'Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø© Ø¹Ø±Ø¨ÙŠØ©',
    source: 'Wiki QA AR',
    type: 'qa',
    size: '~10K pairs',
    language: 'ar',
    license: 'CC BY-SA',
    huggingfaceId: 'wiki_qa_ar'
  },
  {
    name: 'Assafir News Articles',
    description: 'Ù…Ù‚Ø§Ù„Ø§Øª ØµØ­ÙŠÙØ© Ø§Ù„Ø³ÙÙŠØ±',
    source: 'Assafir',
    type: 'text',
    size: '~100K articles',
    language: 'ar',
    license: 'Research'
  },
  {
    name: 'OSIAN Corpus',
    description: 'Ù…Ø¬Ù…ÙˆØ¹Ø© Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø©',
    source: 'OSIAN',
    type: 'text',
    size: '~10GB',
    language: 'ar',
    license: 'Research'
  }
];

/**
 * Ù…Ø¯ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
 */
export class ArabicDatasetsManager {
  private datasetsDir: string;
  private downloadedDatasets: Map<string, DatasetInfo>;

  constructor(datasetsDir: string = './datasets') {
    this.datasetsDir = datasetsDir;
    this.downloadedDatasets = new Map();
    this.ensureDirectoryExists();
  }

  /**
   * Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯
   */
  private ensureDirectoryExists(): void {
    if (!fs.existsSync(this.datasetsDir)) {
      fs.mkdirSync(this.datasetsDir, { recursive: true });
      console.log(`âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: ${this.datasetsDir}`);
    }
  }

  /**
   * Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
   */
  listAvailableDatasets(): void {
    console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
    console.log('â•‘           Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©                     â•‘');
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    ARABIC_DATASETS.forEach((dataset, index) => {
      console.log(`${index + 1}. ${dataset.name}`);
      console.log(`   Ø§Ù„ÙˆØµÙ: ${dataset.description}`);
      console.log(`   Ø§Ù„Ù†ÙˆØ¹: ${dataset.type}`);
      console.log(`   Ø§Ù„Ø­Ø¬Ù…: ${dataset.size}`);
      console.log(`   Ø§Ù„Ù„ØºØ©: ${dataset.language}`);
      console.log(`   Ø§Ù„ØªØ±Ø®ÙŠØµ: ${dataset.license}`);
      if (dataset.huggingfaceId) {
        console.log(`   ğŸ¤— HuggingFace: ${dataset.huggingfaceId}`);
      }
      if (dataset.downloadUrl) {
        console.log(`   ğŸ”— Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„: ${dataset.downloadUrl}`);
      }
      console.log();
    });
  }

  /**
   * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø§Ø³Ù…
   */
  getDatasetByName(name: string): DatasetInfo | undefined {
    return ARABIC_DATASETS.find(d => d.name === name);
  }

  /**
   * ØªØµÙÙŠØ© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
   */
  filterByType(type: string): DatasetInfo[] {
    return ARABIC_DATASETS.filter(d => d.type === type);
  }

  /**
   * ØªØµÙÙŠØ© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©
   */
  filterByLanguage(language: string): DatasetInfo[] {
    return ARABIC_DATASETS.filter(d => d.language === language);
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
   */
  generateDownloadInstructions(): void {
    const instructionsPath = path.join(this.datasetsDir, 'DOWNLOAD_INSTRUCTIONS.md');
    
    let content = '# ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n';
    content += '# Arabic Datasets Download Instructions\n\n';
    content += '---\n\n';
    content += '## ğŸ“‹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©\n\n';

    ARABIC_DATASETS.forEach((dataset, index) => {
      content += `### ${index + 1}. ${dataset.name}\n\n`;
      content += `**Ø§Ù„ÙˆØµÙ**: ${dataset.description}\n\n`;
      content += `**Ø§Ù„Ù†ÙˆØ¹**: ${dataset.type}\n`;
      content += `**Ø§Ù„Ø­Ø¬Ù…**: ${dataset.size}\n`;
      content += `**Ø§Ù„Ù„ØºØ©**: ${dataset.language}\n`;
      content += `**Ø§Ù„ØªØ±Ø®ÙŠØµ**: ${dataset.license}\n\n`;

      if (dataset.huggingfaceId) {
        content += '**Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† HuggingFace**:\n';
        content += '```python\n';
        content += 'from datasets import load_dataset\n';
        content += `dataset = load_dataset("${dataset.huggingfaceId}")\n`;
        content += '```\n\n';
        content += '**Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLI**:\n';
        content += '```bash\n';
        content += `huggingface-cli download ${dataset.huggingfaceId}\n`;
        content += '```\n\n';
      }

      if (dataset.downloadUrl) {
        content += '**Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±**:\n';
        content += '```bash\n';
        content += `wget ${dataset.downloadUrl}\n`;
        content += '```\n\n';
      }

      content += '---\n\n';
    });

    content += '## ğŸ› ï¸ Ø£Ø¯ÙˆØ§Øª Ù…ÙÙŠØ¯Ø©\n\n';
    content += '### ØªØ«Ø¨ÙŠØª HuggingFace CLI\n';
    content += '```bash\n';
    content += 'pip install huggingface_hub\n';
    content += '```\n\n';

    content += '### ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© datasets\n';
    content += '```bash\n';
    content += 'pip install datasets\n';
    content += '```\n\n';

    content += '## ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª\n\n';
    content += `- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ${ARABIC_DATASETS.length}\n`;
    content += `- **Ù†ØµÙŠØ©**: ${this.filterByType('text').length}\n`;
    content += `- **ØµÙˆØªÙŠØ©**: ${this.filterByType('speech').length}\n`;
    content += `- **Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø©**: ${this.filterByType('qa').length}\n`;
    content += `- **ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø±**: ${this.filterByType('sentiment').length}\n\n`;

    fs.writeFileSync(instructionsPath, content, 'utf-8');
    console.log(`âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: ${instructionsPath}`);
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª ØªØ­Ù…ÙŠÙ„ Python
   */
  generatePythonDownloadScript(): void {
    const scriptPath = path.join(this.datasetsDir, 'download_datasets.py');
    
    let content = '#!/usr/bin/env python3\n';
    content += '# -*- coding: utf-8 -*-\n';
    content += '"""\n';
    content += 'Ø³ÙƒØ±ÙŠØ¨Øª ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n';
    content += 'Arabic Datasets Download Script\n';
    content += '"""\n\n';
    content += 'from datasets import load_dataset\n';
    content += 'import os\n\n';
    content += 'def download_dataset(dataset_id, save_path):\n';
    content += '    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† HuggingFace"""\n';
    content += '    print(f"ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„: {dataset_id}")\n';
    content += '    try:\n';
    content += '        dataset = load_dataset(dataset_id)\n';
    content += '        dataset.save_to_disk(save_path)\n';
    content += '        print(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­: {save_path}")\n';
    content += '        return True\n';
    content += '    except Exception as e:\n';
    content += '        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {e}")\n';
    content += '        return False\n\n';
    content += 'def main():\n';
    content += '    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""\n';
    content += '    datasets_to_download = [\n';

    ARABIC_DATASETS.filter(d => d.huggingfaceId).forEach(dataset => {
      content += `        ("${dataset.huggingfaceId}", "${dataset.name.replace(/\s+/g, '_')}"),\n`;
    });

    content += '    ]\n\n';
    content += '    for dataset_id, name in datasets_to_download:\n';
    content += '        save_path = os.path.join("./", name)\n';
    content += '        download_dataset(dataset_id, save_path)\n\n';
    content += 'if __name__ == "__main__":\n';
    content += '    main()\n';

    fs.writeFileSync(scriptPath, content, 'utf-8');
    fs.chmodSync(scriptPath, '755');
    console.log(`âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Python: ${scriptPath}`);
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù README
   */
  generateReadme(): void {
    const readmePath = path.join(this.datasetsDir, 'README.md');
    
    let content = '# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n';
    content += '# Arabic Training Datasets\n\n';
    content += '---\n\n';
    content += '## ğŸ¯ Ø§Ù„Ù‡Ø¯Ù\n\n';
    content += 'Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø±Ø¨ÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ ÙÙŠ Ù„ØºØ© Ø§Ù„Ø¨ÙŠØ§Ù†.\n\n';
    content += '## ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª\n\n';
    content += `- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©**: ${ARABIC_DATASETS.length}\n`;
    content += `- **Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ**: ~350GB+\n`;
    content += `- **Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ**: ~2 Ù…Ù„ÙŠØ§Ø± ÙƒÙ„Ù…Ø©\n\n`;
    content += '## ğŸ“ Ø§Ù„Ø¨Ù†ÙŠØ©\n\n';
    content += '```\n';
    content += 'datasets/\n';
    content += 'â”œâ”€â”€ README.md                    # Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù\n';
    content += 'â”œâ”€â”€ DOWNLOAD_INSTRUCTIONS.md     # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„\n';
    content += 'â”œâ”€â”€ download_datasets.py         # Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„\n';
    content += 'â”œâ”€â”€ Arabic_Wikipedia/            # ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n';
    content += 'â”œâ”€â”€ OSCAR_Arabic/                # OSCAR\n';
    content += 'â”œâ”€â”€ AraBERT_Dataset/             # AraBERT\n';
    content += 'â””â”€â”€ ...\n';
    content += '```\n\n';
    content += '## ğŸš€ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹\n\n';
    content += '### 1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª\n';
    content += '```bash\n';
    content += 'pip install datasets huggingface_hub\n';
    content += '```\n\n';
    content += '### 2. ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª\n';
    content += '```bash\n';
    content += 'python download_datasets.py\n';
    content += '```\n\n';
    content += '### 3. Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n';
    content += '```typescript\n';
    content += 'import { LogicTrainingSystem } from "../training/logic-training-system";\n\n';
    content += 'const trainer = new LogicTrainingSystem();\n';
    content += 'await trainer.loadDataset("./datasets/Arabic_Wikipedia");\n';
    content += 'await trainer.train();\n';
    content += '```\n\n';
    content += '## ğŸ“š Ø§Ù„Ù…ØµØ§Ø¯Ø±\n\n';
    content += '- [HuggingFace Datasets](https://huggingface.co/datasets)\n';
    content += '- [Arabic NLP Resources](https://github.com/NNLP-IL/Arabic-Resources)\n';
    content += '- [AraBERT](https://github.com/aub-mind/arabert)\n';
    content += '- [CAMeLBERT](https://github.com/CAMeL-Lab/CAMeLBERT)\n\n';
    content += '## âš–ï¸ Ø§Ù„ØªØ±Ø§Ø®ÙŠØµ\n\n';
    content += 'ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© ØªØ±Ø®ÙŠØµ ÙƒÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…. Ù…Ø¹Ø¸Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± Ù„Ù„Ø£Ø¨Ø­Ø§Ø«.\n\n';
    content += '---\n\n';
    content += '**Â© 2025 Basel Yahya Abdullah - Bayan Language Project**\n';

    fs.writeFileSync(readmePath, content, 'utf-8');
    console.log(`âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù README: ${readmePath}`);
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
   */
  generateAllFiles(): void {
    console.log('\nğŸš€ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n');
    
    this.generateDownloadInstructions();
    this.generatePythonDownloadScript();
    this.generateReadme();
    
    console.log('\nâœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­!\n');
    console.log(`ğŸ“ Ø§Ù„Ù…Ø¬Ù„Ø¯: ${this.datasetsDir}\n`);
  }
}

// ØªØµØ¯ÙŠØ±
export default ArabicDatasetsManager;

